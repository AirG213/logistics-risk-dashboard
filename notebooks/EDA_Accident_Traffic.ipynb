{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61128e6",
   "metadata": {},
   "source": [
    "# 📊 Analyse des accidents de la circulation aux États-Unis (2016–2023)\n",
    "\n",
    "Ce notebook fait partie du pipeline **R&D Résilience Logistique**.  \n",
    "Il se concentre sur le **module risque routier**, en explorant et nettoyant le dataset **US Accidents** pour fournir des indicateurs exploitables dans le tableau de bord final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf01c93",
   "metadata": {},
   "source": [
    "## 📁 Structure du dataset\n",
    "\n",
    "| Variable             | Description courte                                                 | Type    | Exemples                    |\n",
    "| -------------------- | ------------------------------------------------------------------ | ------- | --------------------------- |\n",
    "| `ID`                 | Identifiant unique de l'accident                                   | object  | 'A-1', 'A-2'                |\n",
    "| `Source`             | Source de la donnée (ex: capteur, site partenaire)                 | object  | 'Source2'                   |\n",
    "| `Severity`           | Gravité de l'accident (1 à 4)                                      | int     | 2, 3                        |\n",
    "| `Start_Time`         | Date et heure de début de l'accident                               | datetime| '2016-02-08 05:46:00'       |\n",
    "| `End_Time`           | Date et heure de fin de l'accident                                 | datetime| '2016-02-08 11:00:00'       |\n",
    "| `Start_Lat`          | Latitude de début                                                  | float   | 39.865147                   |\n",
    "| `Start_Lng`          | Longitude de début                                                 | float   | -84.058723                  |\n",
    "| `End_Lat`            | Latitude de fin (souvent manquante)                                | float   | -                           |\n",
    "| `End_Lng`            | Longitude de fin (souvent manquante)                               | float   | -                           |\n",
    "| `Distance(mi)`       | Distance couverte par l'incident                                   | float   | 0.01                        |\n",
    "| `Description`        | Description textuelle de l'événement                               | object  | 'Accident sur I-70 E...'    |\n",
    "| `Street`, `City`, `County`, `State`, `Zipcode`, `Country` | Localisation administrative                    | object  | 'Dayton', 'Montgomery', 'OH'|\n",
    "| `Timezone`           | Fuseau horaire local                                               | object  | 'US/Eastern'                |\n",
    "| `Airport_Code`       | Code de l'aéroport le plus proche                                  | object  | 'KFFO'                      |\n",
    "| `Weather_Timestamp`  | Timestamp météo associé                                            | datetime| '2016-02-08 05:58:00'       |\n",
    "| `Temperature(F)`     | Température en Fahrenheit                                          | float   | 36.9                        |\n",
    "| `Wind_Chill(F)`      | Ressenti en Fahrenheit                                             | float   | 33.3                        |\n",
    "| `Humidity(%)`        | Taux d'humidité                                                    | float   | 91.0                        |\n",
    "| `Pressure(in)`       | Pression atmosphérique en pouces                                   | float   | 29.68                       |\n",
    "| `Visibility(mi)`     | Visibilité en miles                                                | float   | 10.0                        |\n",
    "| `Wind_Direction`     | Direction du vent                                                  | object  | 'Calm', 'SW'                |\n",
    "| `Wind_Speed(mph)`    | Vitesse du vent en mph                                             | float   | 3.5                         |\n",
    "| `Precipitation(in)`  | Précipitations en pouces                                           | float   | 0.02                        |\n",
    "| `Weather_Condition`  | Conditions météo décrites                                          | object  | 'Light Rain', 'Overcast'    |\n",
    "| `Amenity` à `Turning_Loop` | Divers indicateurs routiers booléens (bump, stop, signal, etc.) | bool    | True / False                |\n",
    "| `Sunrise_Sunset` à `Astronomical_Twilight` | Phase de la journée                          | object  | 'Day', 'Night'              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284a5f1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac37113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from meteostat import Stations, Daily, Hourly\n",
    "\n",
    "# Réglages pandas & seaborn\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"Librairies chargées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872997af",
   "metadata": {},
   "source": [
    "# Chargement des données + premières vérifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le chemin du fichier\n",
    "file_path = \"../data/extracted/USA_Accidents_Traffic/US_Accidents_March23.csv\"\n",
    "\n",
    "# Chargement du CSV\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Vérifier dimensions et aperçu\n",
    "print(f\"Dimensions de df : {df.shape}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676042ae",
   "metadata": {},
   "source": [
    "# Vérification détaillée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac379e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche infos générales : types, nulls\n",
    "df.info()\n",
    "\n",
    "# Statistiques descriptives pour colonnes numériques\n",
    "df.describe().T\n",
    "\n",
    "# Liste complète des colonnes pour préparer le tableau résumé\n",
    "print(\"\\nListe des colonnes :\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d44c7f",
   "metadata": {},
   "source": [
    "# Vérification des doublons et valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff5c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le nombre de doublons basés sur l'ID\n",
    "nb_duplicated = df.duplicated(subset='ID').sum()\n",
    "print(f\"Nombre de doublons basés sur 'ID' : {nb_duplicated}\")\n",
    "\n",
    "# Vérifier le pourcentage de valeurs manquantes par colonne\n",
    "missing_ratio = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "print(\"Pourcentage de valeurs manquantes par colonne (top 10) :\")\n",
    "print(missing_ratio.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e5ac8",
   "metadata": {},
   "source": [
    "# Conversion des colonnes temporelles + création de Duration(min)\n",
    "## Objectifs :\n",
    "- Convertir Start_Time et End_Time en datetime\n",
    "- Créer la durée en minutes (Duration(min))\n",
    "- Filtrer les durées aberrantes (exemple : négatives ou trop extrêmes si nécessaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir et calculer pour inspecter\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')\n",
    "\n",
    "# Création de la durée en minutes\n",
    "df['Duration(min)'] = (df['End_Time'] - df['Start_Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Vérifier les stats de durée pour décider ensuite quoi faire\n",
    "print(df['Duration(min)'].describe())\n",
    "\n",
    "# Vérifier combien de lignes ont une durée négative ou extrême (> 2 jours)\n",
    "print(\"\\nNombre de lignes avec durée négative :\", (df['Duration(min)'] < 0).sum())\n",
    "print(\"Nombre de lignes avec durée > 2 jours :\", (df['Duration(min)'] > 2880).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier combien de lignes ont Start_Time ou End_Time manquant\n",
    "missing_start = df['Start_Time'].isnull().sum()\n",
    "missing_end = df['End_Time'].isnull().sum()\n",
    "\n",
    "print(f\"Lignes sans Start_Time : {missing_start}\")\n",
    "print(f\"Lignes sans End_Time : {missing_end}\")\n",
    "\n",
    "# Supprimer ces lignes car sans datetime = pas de durée => inutile pour tableau de bord\n",
    "initial_shape = df.shape\n",
    "df = df.dropna(subset=['Start_Time', 'End_Time'])\n",
    "print(f\"Lignes supprimées car Start/End manquant : {initial_shape[0] - df.shape[0]}\")\n",
    "\n",
    "# Filtrer les durées extrêmes (> 2 jours) si nécessaire\n",
    "print(f\"Lignes avant filtrage des durées extrêmes : {df.shape[0]}\")\n",
    "df = df[df['Duration(min)'] <= 2880]\n",
    "print(f\"Lignes après filtrage des durées extrêmes : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d3739",
   "metadata": {},
   "source": [
    "# Distribution de la gravité (Severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='Severity', order=sorted(df['Severity'].unique()))\n",
    "plt.title('Répartition des niveaux de gravité (Severity)')\n",
    "plt.xlabel('Gravité')\n",
    "plt.ylabel('Nombre d\\'accidents')\n",
    "plt.show()\n",
    "\n",
    "# Répartition en pourcentage pour contrôle rapide\n",
    "severity_counts = df['Severity'].value_counts(normalize=True) * 100\n",
    "print(\"Proportion de chaque gravité (%):\")\n",
    "print(severity_counts.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution de la durée des accidents (log-scale pour lisibilité)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['Duration(min)'], bins=100)\n",
    "plt.yscale('log')\n",
    "plt.title(\"Distribution des durées d'accidents (minutes)\")\n",
    "plt.xlabel(\"Durée (min)\")\n",
    "plt.ylabel(\"Nombre d'incidents (log scale)\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher les principaux percentiles pour une synthèse rapide\n",
    "duration_percentiles = df['Duration(min)'].quantile([0.5, 0.75, 0.9, 0.95, 0.99])\n",
    "print(\"Percentiles clés des durées (min):\")\n",
    "print(duration_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c601e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la colonne HourOfDay\n",
    "df['HourOfDay'] = df['Start_Time'].dt.hour\n",
    "\n",
    "# Afficher la répartition numérique\n",
    "hour_counts = df['HourOfDay'].value_counts().sort_index()\n",
    "print(\"Répartition du nombre d'accidents par heure :\")\n",
    "print(hour_counts)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='HourOfDay', color='steelblue')\n",
    "plt.title(\"Nombre d'accidents par heure de la journée\")\n",
    "plt.xlabel(\"Heure (0-23)\")\n",
    "plt.ylabel(\"Nombre d'incidents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d693ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la colonne DayOfWeek\n",
    "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek  # 0 = lundi, 6 = dimanche\n",
    "\n",
    "# Afficher la répartition numérique\n",
    "dow_counts = df['DayOfWeek'].value_counts().sort_index()\n",
    "print(\"Répartition du nombre d'accidents par jour de la semaine (0=Lundi) :\")\n",
    "print(dow_counts)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=df, x='DayOfWeek', color='coral')\n",
    "plt.title(\"Nombre d'accidents par jour de la semaine\")\n",
    "plt.xlabel(\"Jour de la semaine (0 = Lundi)\")\n",
    "plt.ylabel(\"Nombre d'incidents\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter Month et Season \n",
    "\n",
    "# Créer la colonne Month\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "\n",
    "# Créer la colonne Season selon des règles simples (hémisphère nord)\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df['Season'] = df['Month'].apply(get_season)\n",
    "\n",
    "# Vérifier les répartitions numériques \n",
    "\n",
    "print(\"\\nRépartition du nombre d'accidents par mois :\")\n",
    "print(df['Month'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nRépartition du nombre d'accidents par saison :\")\n",
    "print(df['Season'].value_counts())\n",
    "\n",
    "# Visualiser \n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(data=df, x='Month', color='skyblue')\n",
    "plt.title(\"Nombre d'accidents par mois\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Nombre d'incidents\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(data=df, x='Season', order=['Winter', 'Spring', 'Summer', 'Fall'], palette='Set2')\n",
    "plt.title(\"Nombre d'accidents par saison\")\n",
    "plt.xlabel(\"Saison\")\n",
    "plt.ylabel(\"Nombre d'incidents\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les colonnes numériques pertinentes\n",
    "num_cols = [\n",
    "    'Severity', 'Duration(min)', \n",
    "    'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', \n",
    "    'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', \n",
    "    'Precipitation(in)'\n",
    "]\n",
    "\n",
    "# Vérifier les colonnes présentes\n",
    "print(f\"Colonnes analysées : {num_cols}\")\n",
    "\n",
    "# Calculer la matrice de corrélation (Spearman plus robuste pour données non linéaires)\n",
    "corr_matrix = df[num_cols].corr(method='spearman')\n",
    "\n",
    "# Afficher la heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Corrélation Spearman entre facteurs et gravité (Severity)\")\n",
    "plt.show()\n",
    "\n",
    "# Extraire et afficher le top 5 des facteurs corrélés à la gravité (hors self-corrélation)\n",
    "severity_corr = corr_matrix['Severity'].drop('Severity').abs().sort_values(ascending=False)\n",
    "print(\"\\nTop 5 des variables les plus corrélées à la gravité :\")\n",
    "print(severity_corr.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e21a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot du top 5 à partir de severity_corr\n",
    "top_corr = severity_corr.head(5)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=top_corr.values, y=top_corr.index, palette=\"Blues_d\")\n",
    "plt.title(\"Top 5 des facteurs corrélés à la gravité (|corr|)\")\n",
    "plt.xlabel(\"Coefficient de corrélation absolu (Spearman)\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher les valeurs exactes pour contrôle\n",
    "print(\"Top 5 des facteurs corrélés à la gravité :\")\n",
    "print(top_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation Severity sur [0,1] (1-4 --> 0-1)\n",
    "df['Severity_norm'] = (df['Severity'] - 1) / 3\n",
    "\n",
    "# Normalisation Duration sur [0,1] avec seuil max à 2880 min (2 jours)\n",
    "df['Duration_norm'] = df['Duration(min)'] / 2880\n",
    "df['Duration_norm'] = df['Duration_norm'].clip(0, 1)\n",
    "\n",
    "# Marquer une condition météo risquée (simple) : pluie, neige, brouillard, orage\n",
    "risky_conditions = ['Rain', 'Snow', 'Thunderstorm', 'Fog', 'Heavy Rain', 'Heavy Snow', 'Blowing Snow']\n",
    "df['Weather_risk'] = df['Weather_Condition'].apply(\n",
    "    lambda x: any([kw.lower() in str(x).lower() for kw in risky_conditions])\n",
    ").astype(int)\n",
    "\n",
    "# Pondération : parts égales\n",
    "df['Risk_Score'] = (df['Severity_norm'] + df['Duration_norm'] + df['Weather_risk']) / 3\n",
    "\n",
    "# Contrôle : aperçu\n",
    "print(df[['Severity', 'Duration(min)', 'Weather_Condition', 'Severity_norm', 'Duration_norm', 'Weather_risk', 'Risk_Score']].head())\n",
    "print(\"\\nStatistiques du Risk_Score :\")\n",
    "print(df['Risk_Score'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b90a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper par mois\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "\n",
    "resilience_month = df.groupby('Month')['Risk_Score'].mean().reset_index()\n",
    "resilience_month['Resilience_Index'] = 1 - resilience_month['Risk_Score']\n",
    "\n",
    "print(resilience_month)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=resilience_month, x='Month', y='Resilience_Index', marker='o')\n",
    "plt.title(\"Indice de Résilience Logistique par Mois (1 - Risk_Score moyen)\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Resilience Index\")\n",
    "plt.ylim(0.79, 0.84)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d01532",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Mois')\n",
    "ax1.set_ylabel('Risk_Score moyen', color=color)\n",
    "ax1.plot(resilience_month['Month'], resilience_month['Risk_Score'], color=color, marker='o')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Resilience Index', color=color)\n",
    "ax2.plot(resilience_month['Month'], resilience_month['Resilience_Index'], color=color, marker='s')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(\"Risk_Score & Resilience Index par Mois\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap Risk_Score : Mois vs Jour de la semaine\n",
    "\n",
    "# Recalculer si nécessaire\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek  # 0 = Lundi\n",
    "\n",
    "# Grouper\n",
    "heatmap_data = df.groupby(['Month', 'DayOfWeek'])['Risk_Score'].mean().reset_index()\n",
    "\n",
    "# Pivot pour format matrice\n",
    "heatmap_matrix = heatmap_data.pivot(index='DayOfWeek', columns='Month', values='Risk_Score')\n",
    "\n",
    "print(\"\\nRisk_Score moyen par Mois et Jour de la semaine :\")\n",
    "print(heatmap_matrix.round(4))\n",
    "\n",
    "# Afficher la heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heatmap_matrix, annot=True, fmt=\".3f\", cmap=\"YlOrRd\")\n",
    "plt.title(\"Heatmap Risk_Score moyen (Mois vs Jour de la semaine)\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Jour de la semaine (0 = Lundi)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une colonne Resilience_Index = 1 - Risk_Score\n",
    "df['Resilience_Index'] = 1 - df['Risk_Score']\n",
    "\n",
    "# Grouper pour la heatmap\n",
    "heatmap_resilience = df.groupby(['Month', 'DayOfWeek'])['Resilience_Index'].mean().reset_index()\n",
    "heatmap_resilience_matrix = heatmap_resilience.pivot(index='DayOfWeek', columns='Month', values='Resilience_Index')\n",
    "\n",
    "print(\"\\nResilience Index moyen par Mois et Jour de la semaine :\")\n",
    "print(heatmap_resilience_matrix.round(4))\n",
    "\n",
    "# Afficher\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heatmap_resilience_matrix, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Heatmap Resilience Index moyen (Mois vs Jour de la semaine)\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Jour de la semaine (0 = Lundi)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7539bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la colonne 'HourOfDay' à partir de Start_Time\n",
    "df['HourOfDay'] = df['Start_Time'].dt.hour\n",
    "\n",
    "# Calculer Risk_Score moyen et Resilience_Index par heure\n",
    "risk_hour = df.groupby('HourOfDay')['Risk_Score'].mean().reset_index()\n",
    "risk_hour['Resilience_Index'] = 1 - risk_hour['Risk_Score']\n",
    "\n",
    "print(\"\\nRisk_Score et Resilience_Index par heure :\")\n",
    "print(risk_hour)\n",
    "\n",
    "# Afficher : ligne bleue = Risk_Score, ligne rouge = Resilience_Index\n",
    "fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Heure de la journée')\n",
    "ax1.set_ylabel('Risk_Score moyen', color=color)\n",
    "ax1.plot(risk_hour['HourOfDay'], risk_hour['Risk_Score'], marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xticks(range(0,24))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Resilience_Index', color=color)\n",
    "ax2.plot(risk_hour['HourOfDay'], risk_hour['Resilience_Index'], marker='s', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(\"Risk_Score & Resilience_Index par heure de la journée\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir des catégories de risque logistique basées sur la gravité, durée, météo et heure\n",
    "\n",
    "def assign_risk_category(row):\n",
    "    if (row['Severity'] >= 3) and (row['Duration(min)'] > 120):\n",
    "        return 'High Infrastructure Block'\n",
    "    elif row['Weather_Condition'] in ['Heavy Rain', 'Snow', 'Thunderstorm', 'Fog']:\n",
    "        return 'Weather Disruption'\n",
    "    elif row['HourOfDay'] in range(7,10) or row['HourOfDay'] in range(16,20):\n",
    "        return 'Peak Hour Congestion'\n",
    "    else:\n",
    "        return 'Low Impact'\n",
    "\n",
    "# S'assurer qu'on a bien la colonne HourOfDay\n",
    "df['HourOfDay'] = df['Start_Time'].dt.hour\n",
    "\n",
    "# Appliquer la fonction\n",
    "df['Risk_Category'] = df.apply(assign_risk_category, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476da900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul final propre\n",
    "risk_summary = df['Risk_Category'].value_counts().reset_index()\n",
    "risk_summary.columns = ['Risk_Category', 'Count']\n",
    "risk_summary['Proportion (%)'] = (risk_summary['Count'] / df.shape[0] * 100).round(2)\n",
    "\n",
    "print(\"\\nRépartition finale des catégories de risque logistique\")\n",
    "print(risk_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e12f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(\n",
    "    data=risk_summary, \n",
    "    y=\"Risk_Category\", \n",
    "    x=\"Count\", \n",
    "    hue=\"Risk_Category\",  # Fix pour éviter le FutureWarning\n",
    "    dodge=False,          # pour éviter le doublement\n",
    "    palette=\"Set2\",\n",
    "    legend=False\n",
    ")\n",
    "plt.title(\"Répartition finale des types de risque logistique (catégories)\")\n",
    "plt.xlabel(\"Nombre d'incidents\")\n",
    "plt.ylabel(\"Catégorie de risque\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne par mois\n",
    "summary_month = df.groupby('Month')['Risk_Score'].agg(['mean']).reset_index()\n",
    "summary_month.rename(columns={'mean': 'Risk_Score_mean'}, inplace=True)\n",
    "summary_month['Resilience_Index_mean'] = 1 - summary_month['Risk_Score_mean']\n",
    "\n",
    "# Moyenne par jour de la semaine\n",
    "summary_dayofweek = df.groupby('DayOfWeek')['Risk_Score'].agg(['mean']).reset_index()\n",
    "summary_dayofweek.rename(columns={'mean': 'Risk_Score_mean'}, inplace=True)\n",
    "summary_dayofweek['Resilience_Index_mean'] = 1 - summary_dayofweek['Risk_Score_mean']\n",
    "\n",
    "# Moyenne par heure de la journée\n",
    "summary_hourofday = df.groupby('HourOfDay')['Risk_Score'].agg(['mean']).reset_index()\n",
    "summary_hourofday.rename(columns={'mean': 'Risk_Score_mean'}, inplace=True)\n",
    "summary_hourofday['Resilience_Index_mean'] = 1 - summary_hourofday['Risk_Score_mean']\n",
    "\n",
    "# Moyenne par catégorie de risque\n",
    "summary_category = df.groupby('Risk_Category')['Risk_Score'].agg(['mean', 'count']).reset_index()\n",
    "summary_category.rename(columns={'mean': 'Risk_Score_mean', 'count': 'Count'}, inplace=True)\n",
    "summary_category['Resilience_Index_mean'] = 1 - summary_category['Risk_Score_mean']\n",
    "summary_category['Proportion'] = summary_category['Count'] / summary_category['Count'].sum()\n",
    "\n",
    "# Afficher un échantillon pour vérif rapide\n",
    "print(\"\\nMoyenne par mois ===\")\n",
    "print(summary_month)\n",
    "\n",
    "print(\"\\nMoyenne par jour de la semaine ===\")\n",
    "print(summary_dayofweek)\n",
    "\n",
    "print(\"\\nMoyenne par heure de la journée ===\")\n",
    "print(summary_hourofday)\n",
    "\n",
    "print(\"\\nMoyenne par catégorie de risque ===\")\n",
    "print(summary_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6298b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour graphe par mois\n",
    "risk_by_month = df.groupby('Month')['Risk_Score'].mean()\n",
    "resilience_by_month = 1 - risk_by_month\n",
    "\n",
    "# Idem pour jour de semaine et heure\n",
    "risk_by_day = df.groupby('DayOfWeek')['Risk_Score'].mean()\n",
    "resilience_by_day = 1 - risk_by_day\n",
    "\n",
    "risk_by_hour = df.groupby('HourOfDay')['Risk_Score'].mean()\n",
    "resilience_by_hour = 1 - risk_by_hour\n",
    "\n",
    "risk_by_cat = df.groupby('Risk_Category')['Risk_Score'].mean()\n",
    "resilience_by_cat = 1 - risk_by_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "\n",
    "# Définir palette\n",
    "risk_color = \"#e74c3c\"\n",
    "resilience_color = \"#27ae60\"\n",
    "\n",
    "# Risque & Résilience par Mois ---\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_month['Month'], df_month['Risk_Score_mean'], '-o', label='Risque', color=risk_color, linewidth=2.5)\n",
    "plt.plot(df_month['Month'], df_month['Resilience_Index_mean'], '-o', label='Résilience', color=resilience_color, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Indice de Risque et de Résilience par Mois\")\n",
    "plt.xlabel(\"Mois\")\n",
    "plt.ylabel(\"Score (0-1)\")\n",
    "plt.xticks(df_month['Month'])\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Risque & Résilience par Jour de la semaine ---\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_day['DayOfWeek'], df_day['Risk_Score_mean'], '-o', label='Risque', color=risk_color, linewidth=2.5)\n",
    "plt.plot(df_day['DayOfWeek'], df_day['Resilience_Index_mean'], '-o', label='Résilience', color=resilience_color, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Indice de Risque et de Résilience par Jour de la Semaine (0 = Lundi)\")\n",
    "plt.xlabel(\"Jour de la Semaine\")\n",
    "plt.ylabel(\"Score (0-1)\")\n",
    "plt.xticks(df_day['DayOfWeek'], labels=[\"Lun\", \"Mar\", \"Mer\", \"Jeu\", \"Ven\", \"Sam\", \"Dim\"])\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Risque & Résilience par Heure ---\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_hour['HourOfDay'], df_hour['Risk_Score_mean'], '-o', label='Risque', color=risk_color, linewidth=2.5)\n",
    "plt.plot(df_hour['HourOfDay'], df_hour['Resilience_Index_mean'], '-o', label='Résilience', color=resilience_color, linewidth=2.5)\n",
    "\n",
    "plt.title(\"Indice de Risque et de Résilience par Heure de la Journée\")\n",
    "plt.xlabel(\"Heure\")\n",
    "plt.ylabel(\"Score (0-1)\")\n",
    "plt.xticks(df_hour['HourOfDay'])\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Risque & Résilience par Catégorie ---\n",
    "plt.figure(figsize=(12,6))\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(df_cat['Risk_Category']))\n",
    "\n",
    "plt.bar(x - bar_width/2, df_cat['Risk_Score_mean'], width=bar_width, color=risk_color, label='Risque')\n",
    "plt.bar(x + bar_width/2, df_cat['Resilience_Index_mean'], width=bar_width, color=resilience_color, label='Résilience')\n",
    "\n",
    "plt.title(\"Comparaison Risque & Résilience par Catégorie de Risque Logistique\")\n",
    "plt.xlabel(\"Catégorie\")\n",
    "plt.ylabel(\"Score (0-1)\")\n",
    "plt.xticks(x, df_cat['Risk_Category'], rotation=20)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80453368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer Weather Disruption et High Infrastructure Block\n",
    "weather_df = df[df['Risk_Category'] == 'Weather Disruption'].copy()\n",
    "infra_block_df = df[df['Risk_Category'] == 'High Infrastructure Block'].copy()\n",
    "\n",
    "# Afficher nombre de lignes\n",
    "print(f\"Weather Disruption : {weather_df.shape[0]} incidents\")\n",
    "print(f\"High Infrastructure Block : {infra_block_df.shape[0]} incidents\")\n",
    "\n",
    "# Afficher un échantillon\n",
    "print(\"\\nWeather Disruption sample :\")\n",
    "print(weather_df.head(3))\n",
    "\n",
    "print(\"\\nHigh Infrastructure Block sample :\")\n",
    "print(infra_block_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par mois\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "sns.countplot(data=weather_df, x='Month', ax=ax[0])\n",
    "ax[0].set_title(\"Weather Disruption - par Mois\")\n",
    "sns.countplot(data=infra_block_df, x='Month', ax=ax[1])\n",
    "ax[1].set_title(\"High Infrastructure Block - par Mois\")\n",
    "plt.show()\n",
    "\n",
    "# Par jour de la semaine\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "sns.countplot(data=weather_df, x='DayOfWeek', ax=ax[0])\n",
    "ax[0].set_title(\"Weather Disruption - par Jour\")\n",
    "sns.countplot(data=infra_block_df, x='DayOfWeek', ax=ax[1])\n",
    "ax[1].set_title(\"High Infrastructure Block - par Jour\")\n",
    "plt.show()\n",
    "\n",
    "# Par heure\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14,5))\n",
    "sns.countplot(data=weather_df, x='HourOfDay', ax=ax[0])\n",
    "ax[0].set_title(\"Weather Disruption - par Heure\")\n",
    "sns.countplot(data=infra_block_df, x='HourOfDay', ax=ax[1])\n",
    "ax[1].set_title(\"High Infrastructure Block - par Heure\")\n",
    "plt.show()\n",
    "\n",
    "# === B) Conditions météo ===\n",
    "print(\"\\nTop 10 Weather Conditions pour Weather Disruption :\")\n",
    "print(weather_df['Weather_Condition'].value_counts().head(10))\n",
    "\n",
    "# === C) Statistiques Durée et Gravité ===\n",
    "print(\"\\nStats Weather Disruption:\")\n",
    "print(weather_df[['Duration(min)', 'Severity']].describe())\n",
    "\n",
    "print(\"\\nStats High Infrastructure Block:\")\n",
    "print(infra_block_df[['Duration(min)', 'Severity']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conserver uniquement incidents avec Weather Disruption OU Peak Hour Congestion\n",
    "df_heat = df[df['Risk_Category'].isin(['Peak Hour Congestion', 'Weather Disruption'])].copy()\n",
    "\n",
    "# Remplacer 'None' par 'Clear/Other' pour contrôle mais on peut filtrer ensuite\n",
    "df_heat = df_heat[df_heat['Main_Weather'] != 'None']\n",
    "\n",
    "# Si tu veux limiter aux types météo clés uniquement (Rain, Snow, Fog, Thunderstorm)\n",
    "df_heat = df_heat[df_heat['Main_Weather'].isin(['Rain', 'Snow', 'Fog', 'Thunderstorm'])]\n",
    "\n",
    "# Regrouper Risk_Score moyen par heure et météo\n",
    "heatmap_data = df_heat.groupby(['Main_Weather', 'HourOfDay'])['Risk_Score'].mean().reset_index()\n",
    "\n",
    "# Pivot pour heatmap\n",
    "heatmap_matrix = heatmap_data.pivot(index='Main_Weather', columns='HourOfDay', values='Risk_Score')\n",
    "\n",
    "# Tri de l'index pour l'ordre que tu veux\n",
    "heatmap_matrix = heatmap_matrix.loc[['Fog', 'Rain', 'Snow', 'Thunderstorm']]\n",
    "\n",
    "# Afficher\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.heatmap(heatmap_matrix, annot=True, fmt=\".2f\", cmap=\"YlOrRd\")\n",
    "plt.title(\"Heatmap Risque moyen (Weather Conditions vs Heure de la journée)\")\n",
    "plt.xlabel(\"Heure\")\n",
    "plt.ylabel(\"Condition météo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étiquette météo simplifiée pour ceux affectés par la météo\n",
    "conditions = [\n",
    "    df['Risk_Category'] == 'Weather Disruption',\n",
    "]\n",
    "choices = [\n",
    "    df['Weather_Condition'].where(df['Risk_Category'] == 'Weather Disruption', None)\n",
    "]\n",
    "\n",
    "df['Main_Weather'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "# Nettoyer : regrouper les valeurs proches\n",
    "df['Main_Weather'] = df['Main_Weather'].replace({\n",
    "    'Heavy Rain': 'Rain',\n",
    "    'Light Rain': 'Rain',\n",
    "    'Snow': 'Snow',\n",
    "    'Heavy Snow': 'Snow',\n",
    "    'Thunderstorm': 'Thunderstorm',\n",
    "    'Fog': 'Fog'\n",
    "}).fillna('None')\n",
    "\n",
    "# Vérif : risk & resilience sont déjà calculés ===\n",
    "df['Resilience_Index'] = 1 - df['Risk_Score']\n",
    "\n",
    "# Vérif : catégorie risque déjà correcte ===\n",
    "print(df['Risk_Category'].value_counts())\n",
    "\n",
    "\n",
    "# Export \n",
    "cols_to_export = [\n",
    "    'ID', 'Start_Time', 'Severity', 'Duration(min)',\n",
    "    'Risk_Score', 'Resilience_Index', 'Risk_Category',\n",
    "    'Main_Weather',\n",
    "    'Month', 'DayOfWeek', 'HourOfDay'\n",
    "]\n",
    "\n",
    "output_path = \"../data/cleaned/usa_accidents_traffic_cleaned.csv\"\n",
    "df[cols_to_export].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Export fait : {output_path}\")\n",
    "print(f\"Colonnes exportées : {cols_to_export}\")\n",
    "print(f\"Lignes : {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df.shape[0]\n",
    "peak_hour_count = df[df['Risk_Category'] == 'Peak Hour Congestion'].shape[0]\n",
    "infra_block_mean = infra_block_df['Duration(min)'].mean()\n",
    "weather_count = weather_df.shape[0]\n",
    "\n",
    "peak_hour_pct = peak_hour_count / total * 100\n",
    "weather_pct = weather_count / total * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "Synthèse du risque routier :\n",
    "- Plus de {peak_hour_pct:.1f}% des incidents surviennent lors des heures de pointe, ce qui en fait la principale cause de congestion logistique.\n",
    "- Les incidents « Infrastructure Bloquée » représentent des blocages longs, avec une durée moyenne de {infra_block_mean:.0f} minutes.\n",
    "- Les conditions météo sévères sont moins fréquentes ({weather_pct:.1f}% des cas) mais génèrent un risque plus élevé, notamment en cas de neige, brouillard ou orage.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5169a",
   "metadata": {},
   "source": [
    "# Résumé final du module Analyse du Risque Routier\n",
    "\n",
    "## Objectif\n",
    "Ce notebook a permis de nettoyer, structurer et analyser le dataset US Accidents (2016–2023)\n",
    "dans le cadre du pipeline R&D pour mesurer la résilience logistique.\n",
    "L'objectif principal est de fournir un fichier prêt à être intégré dans un tableau de bord.\n",
    "\n",
    "## Ce qui a été fait\n",
    "- Chargement et nettoyage des données : conversion des timestamps, calcul de la durée en minutes,\n",
    "  suppression des valeurs aberrantes (durées négatives ou supérieures à 2 jours).\n",
    "- Exploration descriptive : distribution des niveaux de gravité, distribution des durées,\n",
    "  identification des pics horaires, jours et mois à risque.\n",
    "- Corrélation Spearman pour détecter les variables influentes sur la gravité.\n",
    "- Création d'un score de risque standardisé (Risk_Score) combinant gravité, durée et météo.\n",
    "- Calcul d'un indice de résilience (Resilience_Index) comme complément de l'indice de risque.\n",
    "- Attribution d'une catégorie de risque logistique pour chaque incident :\n",
    "  - Peak Hour Congestion (heures de pointe)\n",
    "  - High Infrastructure Block (incidents bloquants longue durée)\n",
    "  - Weather Disruption (conditions météo critiques)\n",
    "  - Low Impact (autres cas mineurs)\n",
    "- Génération de visualisations pour valider la saisonnalité, la cyclicité horaire et les pics par catégorie.\n",
    "- Export final d'un fichier CSV structuré contenant toutes les colonnes utiles :\n",
    "  ID, Start_Time, Severity, Duration(min), Risk_Score, Resilience_Index, Risk_Category,\n",
    "  Main_Weather (regroupement des conditions météo dominantes), Month, DayOfWeek, HourOfDay.\n",
    "\n",
    "## Analyse synthétique\n",
    "- La majorité des incidents sont classés en Low Impact, avec un risque faible pour la logistique.\n",
    "- Les congestions horaires (matin et fin de journée) représentent environ 42% des incidents.\n",
    "- Les incidents bloquants (High Infrastructure Block) sont rares (environ 3%) mais leur durée\n",
    "  moyenne est élevée (~300 min), ce qui impacte fortement la fluidité des réseaux.\n",
    "- Les perturbations liées à la météo (Weather Disruption) sont limitées (environ 2% des cas) mais\n",
    "  concentrées sur des événements de forte pluie, neige ou brouillard.\n",
    "\n",
    "## Conclusion\n",
    "Ce module fournit une base cohérente pour alimenter un tableau de bord opérationnel permettant\n",
    "de suivre en temps réel ou en historique les risques routiers pour la chaîne logistique.\n",
    "Les indicateurs produits sont prêts pour une visualisation interactive et un croisement éventuel\n",
    "avec d'autres modes de transport."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
