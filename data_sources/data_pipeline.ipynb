{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38a3708",
   "metadata": {
    "papermill": {
     "duration": 0.002417,
     "end_time": "2025-06-24T14:49:36.586397",
     "exception": false,
     "start_time": "2025-06-24T14:49:36.583980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DATA PIPELINE\n",
    "- Etapes : Download ➜ Extract ➜ EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a1db2",
   "metadata": {
    "papermill": {
     "duration": 0.001372,
     "end_time": "2025-06-24T14:49:36.588810",
     "exception": false,
     "start_time": "2025-06-24T14:49:36.587438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Structure des dossiers :\n",
    "- /data/raw/       : ZIP téléchargés\n",
    "- /data/extracted/ : Fichiers extraits par dataset\n",
    "-/data/cleaned/   : Fichiers nettoyés finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b0908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:36.592389Z",
     "iopub.status.busy": "2025-06-24T14:49:36.592389Z",
     "iopub.status.idle": "2025-06-24T14:49:37.109951Z",
     "shell.execute_reply": "2025-06-24T14:49:37.109951Z"
    },
    "papermill": {
     "duration": 0.520725,
     "end_time": "2025-06-24T14:49:37.110959",
     "exception": false,
     "start_time": "2025-06-24T14:49:36.590234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import papermill as pm\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"gabrielcabart\"\n",
    "os.environ[\"KAGGLE_KEY\"] = \"ef2487d4a68ba1c9cf693898c167f3b2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7a5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:37.114536Z",
     "iopub.status.busy": "2025-06-24T14:49:37.113044Z",
     "iopub.status.idle": "2025-06-24T14:49:37.120047Z",
     "shell.execute_reply": "2025-06-24T14:49:37.120047Z"
    },
    "papermill": {
     "duration": 0.008043,
     "end_time": "2025-06-24T14:49:37.120047",
     "exception": false,
     "start_time": "2025-06-24T14:49:37.112004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = Path().resolve().parent \n",
    "\n",
    "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "EXTRACTED_DIR = BASE_DIR / \"data\" / \"extracted\"\n",
    "CLEANED_DIR = BASE_DIR / \"data\" / \"cleaned\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EXTRACTED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEANED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"BASE_DIR: {BASE_DIR}\")\n",
    "print(f\"RAW_DIR: {RAW_DIR}\")\n",
    "print(f\"EXTRACTED_DIR: {EXTRACTED_DIR}\")\n",
    "print(f\"CLEANED_DIR: {CLEANED_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e6c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:37.123451Z",
     "iopub.status.busy": "2025-06-24T14:49:37.123451Z",
     "iopub.status.idle": "2025-06-24T14:49:37.126634Z",
     "shell.execute_reply": "2025-06-24T14:49:37.126634Z"
    },
    "papermill": {
     "duration": 0.005364,
     "end_time": "2025-06-24T14:49:37.126634",
     "exception": false,
     "start_time": "2025-06-24T14:49:37.121270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste des datasets (Slug, Nom ZIP, Nom dossier extrait, Nom du fichier à extraire)\n",
    "DATASETS = [\n",
    "    {\n",
    "        \"slug\": \"sobhanmoosavi/us-accidents\",\n",
    "        \"zip_name\": \"USA_Accidents_Traffic.zip\",\n",
    "        \"extract_dir\": \"USA_Accidents_Traffic\",\n",
    "        \"expected_file\": \"US_Accidents_March23.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"slug\": \"ryanjt/airline-delay-cause\",\n",
    "        \"zip_name\": \"USA_Airline_Delay_Cause.zip\",\n",
    "        \"extract_dir\": \"USA_Airline_Delay_Cause\",\n",
    "        \"expected_file\": \"Airline_Delay_Cause.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"slug\": \"chrico03/railroad-accident-and-incident-data\",\n",
    "        \"zip_name\": \"Railroad_Accident_Incident_Data.zip\",\n",
    "        \"extract_dir\": \"Railroad_Accident_Incident_Data\",\n",
    "        \"expected_file\": \"Rail_Equipment_Accident_Incident_Data.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"slug\": \"natasha0786/supply-chain-dataset\",\n",
    "        \"zip_name\": \"Supply_chain_dataset.zip\",\n",
    "        \"extract_dir\": \"Supply_chain_dataset\",\n",
    "        \"expected_file\": \"dynamic_supply_chain_logistics_dataset_with_country.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"slug\": \"sujalsuthar/amazon-delivery-dataset\",\n",
    "        \"zip_name\": \"Amazon_Delivery_Dataset.zip\",\n",
    "        \"extract_dir\": \"Amazon_Delivery_Dataset\",\n",
    "        \"expected_file\": \"amazon_delivery.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"slug\": \"gabrielcabart/maritime-accidents-and-port-data\",\n",
    "        \"zip_name\": \"Shipping_Accidents.zip\",\n",
    "        \"extract_dir\": \"Shipping_Accidents\",\n",
    "        \"expected_file\": \"Shipping_Accidents.shp\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439af115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:37.130204Z",
     "iopub.status.busy": "2025-06-24T14:49:37.130204Z",
     "iopub.status.idle": "2025-06-24T14:49:37.133891Z",
     "shell.execute_reply": "2025-06-24T14:49:37.133891Z"
    },
    "papermill": {
     "duration": 0.006936,
     "end_time": "2025-06-24T14:49:37.135022",
     "exception": false,
     "start_time": "2025-06-24T14:49:37.128086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Téléchargement pour chaque dataset\n",
    "for ds in DATASETS:\n",
    "    zip_path = RAW_DIR / ds[\"zip_name\"]\n",
    "\n",
    "    if zip_path.exists():\n",
    "        print(f\"✅ {ds['zip_name']} déjà présent.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"⬇️  Téléchargement de {ds['zip_name']} ...\")\n",
    "\n",
    "    try:\n",
    "        # Forcer le bon nom dès le téléchargement :\n",
    "        subprocess.run(\n",
    "            [\n",
    "                \"kaggle\", \"datasets\", \"download\",\n",
    "                \"-d\", ds[\"slug\"],\n",
    "                \"-p\", str(RAW_DIR)\n",
    "            ],\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Kaggle télécharge souvent avec le nom du slug → on renomme au standard si besoin :\n",
    "        downloaded_default_name = RAW_DIR / (ds[\"slug\"].split(\"/\")[-1] + \".zip\")\n",
    "\n",
    "        if downloaded_default_name.exists() and downloaded_default_name != zip_path:\n",
    "            downloaded_default_name.rename(zip_path)\n",
    "            print(f\"✅ Fichier renommé : {downloaded_default_name.name} → {zip_path.name}\")\n",
    "\n",
    "        print(f\"✅ Téléchargement terminé : {zip_path.name}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Erreur lors du téléchargement de {ds['zip_name']} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67fd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:37.138161Z",
     "iopub.status.busy": "2025-06-24T14:49:37.138161Z",
     "iopub.status.idle": "2025-06-24T14:49:37.142677Z",
     "shell.execute_reply": "2025-06-24T14:49:37.142677Z"
    },
    "papermill": {
     "duration": 0.007665,
     "end_time": "2025-06-24T14:49:37.143683",
     "exception": false,
     "start_time": "2025-06-24T14:49:37.136018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXTRACTION : pour chaque ZIP de /data/raw/\n",
    "for ds in DATASETS:\n",
    "    zip_path = RAW_DIR / ds[\"zip_name\"]\n",
    "    dest_dir = EXTRACTED_DIR / ds[\"extract_dir\"]\n",
    "    expected_file = dest_dir / ds[\"expected_file\"]\n",
    "\n",
    "    if expected_file.exists():\n",
    "        print(f\"✅ {expected_file.name} déjà extrait dans {dest_dir.name}.\")\n",
    "        continue\n",
    "\n",
    "    # Assure le dossier cible\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"Extraction de {zip_path.name} vers {dest_dir} ...\")\n",
    "\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "        if expected_file.exists():\n",
    "            print(f\"✅ Extraction terminée : {expected_file.name}\")\n",
    "        else:\n",
    "            print(f\"⚠️ Extraction faite mais {expected_file.name} introuvable — vérifie le contenu.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'extraction de {zip_path.name} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d12685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T14:49:37.146682Z",
     "iopub.status.busy": "2025-06-24T14:49:37.146682Z",
     "iopub.status.idle": "2025-06-24T14:49:37.152271Z",
     "shell.execute_reply": "2025-06-24T14:49:37.152271Z"
    },
    "papermill": {
     "duration": 0.007588,
     "end_time": "2025-06-24T14:49:37.152271",
     "exception": false,
     "start_time": "2025-06-24T14:49:37.144683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dossier où sont les notebooks EDA\n",
    "NOTEBOOKS_DIR = BASE_DIR / \"notebooks\"\n",
    "\n",
    "# Mapping : notebook EDA, fichier nettoyé attendu\n",
    "EDA_TASKS = [\n",
    "    {\n",
    "        \"notebook\": \"EDA_Accident_Traffic.ipynb\",\n",
    "        \"cleaned\": \"usa_accidents_traffic_cleaned.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"notebook\": \"EDA_Airline_Delay_Cause.ipynb\",\n",
    "        \"cleaned\": \"airline_delay_cause_cleaned.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"notebook\": \"EDA_Amazon_Delivery_Dataset.ipynb\",\n",
    "        \"cleaned\": \"amazon_delivery_cleaned.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"notebook\": \"EDA_Railroad_Accident_Incident_Data.ipynb\",\n",
    "        \"cleaned\": \"railroad_accident_cleaned.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"notebook\": \"EDA_Supply_chain_dataset.ipynb\",\n",
    "        \"cleaned\": \"supply_chain_cleaned.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"notebook\": \"EDA_Shipping_Accidents.ipynb\",\n",
    "        \"cleaned\": \"shipping_accidents_cleaned.csv\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Exécution EDA pour chaque notebook\n",
    "for task in EDA_TASKS:\n",
    "    notebook_path = NOTEBOOKS_DIR / task[\"notebook\"]\n",
    "    cleaned_path = CLEANED_DIR / task[\"cleaned\"]\n",
    "\n",
    "    if cleaned_path.exists():\n",
    "        print(f\"✅ {cleaned_path.name} déjà généré. Skip.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Exécution de {task['notebook']} ...\")\n",
    "\n",
    "    try:\n",
    "        pm.execute_notebook(\n",
    "            input_path=str(notebook_path),\n",
    "            output_path=None, \n",
    "            parameters={}\n",
    "        )\n",
    "        print(f\"✅ EDA terminé pour : {task['notebook']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de l'exécution de {task['notebook']}: {e}\")\n",
    "\n",
    "print(\"\\n=== ✅ TOUS LES EDA SONT TERMINÉS ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.642577,
   "end_time": "2025-06-24T14:49:37.395609",
   "environment_variables": {},
   "exception": null,
   "input_path": "C:\\git\\logistics-risk-dashboard\\data_sources\\data_pipeline.ipynb",
   "output_path": "C:\\git\\logistics-risk-dashboard\\data_sources\\data_pipeline.ipynb",
   "parameters": {},
   "start_time": "2025-06-24T14:49:34.753032",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
